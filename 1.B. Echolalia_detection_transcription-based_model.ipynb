{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "188155f3",
   "metadata": {},
   "source": [
    "# Transcription-based model for echolalia detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccc10c",
   "metadata": {},
   "source": [
    "The following function, `transcription_model_echolalia`, takes as input a transcription of a multi-speaker audio in **.TextGrid** format. The speech of each speaker should be transcribed in a different tier, and the tier of the child under scope should be named **'AC'** (Autistic Child). Please remove any tiers that contain other content than transcriptions from the input file. The function will return a **dataframe** containing the prediction ('echolalic' or 'non-echolalic') for each utterance pair with additional information about the timestamps of the utterances, the speaker of the source utterances, etcetera. Moreover, a **new .TextGrid** is produced on the basis of the input .TextGrid, that contains annotations of the echolalic utterance pairs in two new tiers: 'source' and 'echolalia'. The path to this new file needs to be specified in the parameter 'output path'. Other parameters are the language (supported: 'nl' (Dutch) and 'fr' (French); for other languages, the user needs to specify a new list of words that need to be disregarded in `to_delete`), the threshold of the amount of common content words that is needed for an echolalic utterance pair (default: 1), and 'allow_overlap'. 'Allow_overlap', *True* by default, specifies whether the model can consider utterances that begin for the start of the AC's utterance but continue when the AC is already speaking as source utterances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd27d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcription_model_echolalia(textgrid_file, output_path, language='nl', threshold=1, allow_overlap=True):\n",
    "    \"\"\"Takes a TextGrid file of the transcription of an audio file as input, \n",
    "    makes a prediction on the label (echolalic or not) for each suitable utterance-pair\n",
    "    and returns a dataframe containing these predictions for each pair,\n",
    "    along with an annotation of the predictions in a new TextGrid\"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import pandas as pd\n",
    "    from praatio import textgrid\n",
    "    import re\n",
    "    import spacy\n",
    "    import string\n",
    "    import tgt\n",
    "    \n",
    "    # Load the spacy model and prepare the extraction of speech intervals\n",
    "    nlp= spacy.load(f'{language}_core_news_sm')\n",
    "        \n",
    "    def get_entries(tier):\n",
    "        \"\"\"Takes tier name as input\n",
    "        and returns the entry dictionary for that tier\"\"\"\n",
    "        tg= textgrid.openTextgrid(textgrid_file, False)\n",
    "\n",
    "        return tg.getTier(tier).entries\n",
    "    \n",
    "    def get_speech_intervals(tier):\n",
    "        \"\"\"Takes tier name as input\n",
    "        and returns a dictionary containing the timestamps and transcriptions\n",
    "        of the utterances spoken by the speaker of the tier\"\"\"\n",
    "        \n",
    "        entries= get_entries(tier)\n",
    "        intervals={}\n",
    "        regex= r\"^(xxx|yyy)\\s?(\\[.+\\])?\\.?$\" # Regex that identifies unintelligible utterances; adapt if necessary\n",
    "        for entry in entries:\n",
    "            if not re.match(regex, entry.label):\n",
    "                intervals[entry.start, entry.end]= entry.label\n",
    "\n",
    "        return intervals \n",
    "    \n",
    "    def get_other_speakers():\n",
    "        \"\"\"Finds the names of tiers of other speakers (not 'AC') in the input TextGrid\"\"\"\n",
    "        tg = textgrid.openTextgrid(textgrid_file, includeEmptyIntervals=False)\n",
    "        other_speakers=[]\n",
    "        for tier in tg.tierNames:\n",
    "            if tier != 'AC':\n",
    "                other_speakers.append(tier)\n",
    "        return other_speakers\n",
    "    \n",
    "    def preprocess_string(string):\n",
    "        \"\"\"Takes as input a string and outputs a new string where punctuation,\n",
    "        truncated words and fillers have been removed\"\"\"\n",
    "        \n",
    "        string= string.translate(str.maketrans('','', '+?!,/.()[]'))\n",
    "        if language== 'fr':\n",
    "            to_delete = ['euhm', 'euh', 'uhm', 'mmh', 'xxx', 'eh', 'ben','hein', 'ah', 'bah', 'oh', 'bon']\n",
    "        elif language=='nl':\n",
    "            to_delete = ['euhm', 'euh', 'uhm', 'mmh', 'xxx', 'he', 'hè', 'hé', 'ah', 'oh']\n",
    "        string= ' '.join([word for word in string.split() if word not in to_delete and word[-1]!='-' and word[0]!='-'])\n",
    "        return string\n",
    "    \n",
    "    # Now create the output df and textgrid:\n",
    "\n",
    "    child_intervals = get_speech_intervals('AC')\n",
    "\n",
    "    df= pd.DataFrame(columns=['file','s2_tier', 'AC_int', 's2_int', \n",
    "                              'AC_trans', 's2_trans', 'child_lemmas', 's2_lemmas',\n",
    "                              'predicted_n_lemmas', 'predicted_label'])\n",
    "    \n",
    "    \n",
    "    tg = tgt.io.read_textgrid(textgrid_file, encoding='utf-16')\n",
    "    source_tier = tgt.IntervalTier(start_time=0, name='source')\n",
    "    rep_tier = tgt.IntervalTier(start_time=0, name='echolalia')\n",
    "    all_sources=[]\n",
    "    all_echoes=[]\n",
    "    \n",
    "\n",
    "    row_df=0\n",
    "    \n",
    "    # Iterate over the speaker_data dataframe to compare the utterances of the autistic child\n",
    "    # with those of all other speakers:\n",
    "\n",
    "    for other_speaker in get_other_speakers():\n",
    "        s2_tier= other_speaker\n",
    "\n",
    "        s2_intervals = get_speech_intervals(s2_tier)\n",
    "\n",
    "\n",
    "        for start_child, end_child in child_intervals:\n",
    "\n",
    "            child_int= [start_child, end_child]\n",
    "            \n",
    "            child_trans= child_intervals[start_child, end_child]\n",
    "            new_child_trans= preprocess_string(child_trans)\n",
    "            doc= nlp(new_child_trans)\n",
    "            child_lemmas= [(token.lemma_.lower(), token.pos_) for token in doc] \n",
    "            \n",
    "            \n",
    "\n",
    "            for start_s2, end_s2 in s2_intervals:\n",
    "\n",
    "                s2_int= [start_s2,end_s2]\n",
    "\n",
    "                if 0 < start_child - start_s2 <= 10\\\n",
    "                    and (end_s2 < start_child or allow_overlap==True): # if other speaker interval starts at most 10 seconds before child interval:\n",
    "\n",
    "                    s2_trans= s2_intervals[start_s2,end_s2]\n",
    "                    new_s2_trans= preprocess_string(s2_trans)\n",
    "                    doc= nlp(new_s2_trans)\n",
    "                    s2_lemmas= [(token.lemma_.lower(), token.pos_) for token in doc]\n",
    "                    \n",
    "                    \n",
    "                    # Get predictions\n",
    "                    function_pos= ['PRON','AUX', 'DET','INTJ', 'ADP', 'CCONJ', 'SCONJ', 'PUNCT', 'SYM']\n",
    "                    \n",
    "                    common_lemmas=[]\n",
    "                    common_content_lemmas=[]\n",
    "                    \n",
    "                    for lemma1, pos1 in child_lemmas:\n",
    "                        for lemma2, pos2 in s2_lemmas: \n",
    "                            # Append all identical non-punctuation lemmas to 'common_lemmas'\n",
    "                            if (lemma1, pos1) == (lemma2, pos2) \\\n",
    "                            and lemma1 not in common_lemmas and pos1 not in ['PUNCT', 'SYM']:\n",
    "                                common_lemmas.append(lemma1)\n",
    "                                \n",
    "                                # Append all identical lemmas of content words to 'common_content_lemmas'\n",
    "                                if pos1 not in function_pos and (lemma1, pos1) not in [('pas','ADV'), ('niet','ADV')]\\\n",
    "                                and lemma1 not in common_content_lemmas:\n",
    "                                    common_content_lemmas.append(lemma1)\n",
    "                    \n",
    "                    predicted_n_lemmas= np.nan\n",
    "                    # Check if the number of common content lemmas exceeds the threshold:\n",
    "                    if len(common_content_lemmas) >= threshold:\n",
    "                        predicted_label= 'echolalic'\n",
    "                        predicted_n_lemmas= len(common_lemmas)\n",
    "                    else:\n",
    "                        predicted_label= 'non-echolalic'\n",
    "                    \n",
    "                    \n",
    "                    # Add original and echolalic utterance to the output textgrid if the prediction is 'echolalic'\n",
    "                    \n",
    "                    if predicted_label=='echolalic':\n",
    "                        if s2_int not in all_sources:\n",
    "                            all_sources.append(s2_int)\n",
    "                            source_interval_tg = tgt.Interval(start_time=float(start_s2),\n",
    "                                                          end_time=float(end_s2),\n",
    "                                                          text= 'source')\n",
    "                            source_tier.add_interval(source_interval_tg)\n",
    "                            \n",
    "                        if child_int not in all_echoes:\n",
    "                            all_echoes.append(child_int)\n",
    "                            rep_interval_tg = tgt.Interval(start_time=float(start_child),\n",
    "                                                          end_time=float(end_child),\n",
    "                                                          text= 'echolalic')\n",
    "                            rep_tier.add_interval(rep_interval_tg)\n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                    # Append all features of the utterance pair to the output dataframe:\n",
    "\n",
    "                    df.loc[row_df]= [textgrid_file, s2_tier, str(child_int), str(s2_int),\n",
    "                                    child_trans, s2_trans, child_lemmas, s2_lemmas, \n",
    "                                    predicted_n_lemmas, predicted_label]\n",
    "\n",
    "                    row_df+=1\n",
    "    \n",
    "    # Output the textgrid outside of the loop\n",
    "    tg.add_tier(source_tier)\n",
    "    tg.add_tier(rep_tier)\n",
    "    tgt.write_to_file(tg, output_path, format='short')\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad92a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
